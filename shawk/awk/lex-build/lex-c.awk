#!/usr/bin/awk -f

# Author: Vladimir Dinev
# vld.dinev@gmail.com
# 2022-01-14

# Generates a lexer in C. The lexing strategy is quite simple - the next token
# is determined by switch-ing on the class of the current input character and
# then branching on the value of the next character. When a pattern is needed,
# like a number constant, or an id, this is offloaded to the user by the means
# of callback functions. There are two ways to distinguish between keywords and
# ids - an optimized bsearch(), or a literal if - else if tree. The interface
# to both is the same - after an id has been read you call the function and the
# return value is either the token for the keyword in the lexer write buffer, or
# a user provided default value.

# <script>
function SCRIPT_NAME() {return "lex-c.awk"}
function SCRIPT_VERSION() {return "1.41"}
# </script>

# <out_signature>
function out_signature() {
	out_line(sprintf("// generated by %s %s", SCRIPT_NAME(), SCRIPT_VERSION()))
}
# </out_signature>

# <constant_names>
function N_LEX_GET_CURR_CH() {return npref("lex_get_curr_ch")}
function N_LEX_GET_CURR_TOK() {return npref("lex_get_curr_tok")}
function N_LEX_GET_INPUT_LINE_NO() {return npref("lex_get_input_line_no")}
function N_LEX_GET_INPUT_POS() {return npref("lex_get_input_pos")}
function N_LEX_GET_SAVED() {return npref("lex_get_saved")}
function N_LEX_GET_SAVED_LEN() {return npref("lex_get_saved_len")}
function N_LEX_GET_USR_ARG() {return npref("lex_get_usr_arg")}
function N_LEX_INIT() {return npref("lex_init")}
function N_LEX_MATCH() {return npref("lex_match")}
function N_LEX_NEXT() {return npref("lex_next")}
function N_LEX_PEEK_CH() {return npref("lex_peek_ch")}
function N_LEX_READ_CH() {return npref("lex_read_ch")}
function N_LEX_SAVE_BEGIN() {return npref("lex_save_begin")}
function N_LEX_SAVE_CH() {return npref("lex_save_ch")}
function N_LEX_SAVE_END() {return npref("lex_save_end")}
function N_LEX_STATE() {return npref("lex_state")}
function N_LEX_TOK_TO_STR() {return npref("lex_tok_to_str")}
function N_LEX_USR_GET_INPUT() {return npref("lex_usr_get_input")}
function N_LEX_USR_ON_UNKNOWN_CH() {return npref("lex_usr_on_unknown_ch")}
function N_LEX_INIT_INFO() {return npref("lex_init_info")}
function N_TOK_ID() {return npref("tok_id")}
function N_LEX_KEYWORD_OR_BASE() {return npref("lex_keyword_or_base")}
function N_CHAR_CLS() {return npref("char_cls")}
# </constant_names>

# <out_header>
function out_header(    _hdr) {
	_hdr = toupper(npref_get() "LEX_H")
	out_line("// <lex_header>")
	out_signature()
	out_line(sprintf("#ifndef %s", _hdr))
	out_line(sprintf("#define %s", _hdr))
	out_line()
	out_line("#include <stdbool.h>")
	out_line()
	out_tok_enum()
	out_line()
	out_lex_define()
	out_line()
	out_line("#endif")
	out_line("// </lex_header>")
}
function out_lex_cls_events_memb(    _set, _i, _end, _str) {
	lb_vect_make_set(_set, G_actions_vect, 2)

	out_line("// return text input; when done return \"\", never NULL")
	out_line(sprintf("const char * %s(void * usr_arg);", N_LEX_USR_GET_INPUT()))
	out_line("// user events")
	_end = vect_len(_set)
	for(_i = 1; _i <= _end; ++_i) {
		_str = _set[_i]
		if (match(_str, FCALL())) {
			sub(FCALL(), "", _str)
			out_line(sprintf("%s %s(%s * lex);",
				N_TOK_ID(), npref("lex_usr_" _str), N_LEX_STATE()))
		}
	}
	out_line(sprintf("%s %s(%s * lex);",
		N_TOK_ID(), N_LEX_USR_ON_UNKNOWN_CH(), N_LEX_STATE()))
}
function out_lex_init_info(    _set, _i, _end, _str) {
	out_line(sprintf("typedef struct %s {", N_LEX_INIT_INFO()))
	tabs_inc()
	out_line(sprintf("void * usr_arg;   // the argument to %s()",
		N_LEX_USR_GET_INPUT()))
	out_line(sprintf("char * write_buff;   // %s() saves here",
		N_LEX_SAVE_CH()))
	out_line("uint write_buff_len; // includes the '\\0'")
	tabs_dec()
	out_line(sprintf("} %s;", N_LEX_INIT_INFO()))
	out_line()
	
}
function out_lex_define(    _set, _i, _end, _str) {
	out_line("typedef unsigned int uint;")
	out_line(sprintf("typedef struct %s {", N_LEX_STATE()))
	tabs_inc()
	out_line("const char * input;")
	out_line("uint input_pos;")
	out_line("int curr_ch;")
	out_line(sprintf("%s curr_tok;", N_TOK_ID()))
	out_line("uint input_line;")
	out_line("void * usr_arg;")
	out_line("char * write_buff;")
	out_line("uint write_buff_len;")
	out_line("uint write_buff_pos;")
	tabs_dec()
	out_line(sprintf("} %s;", N_LEX_STATE()))
	out_line()
	out_lex_init_info()
	out_line("// <lex_usr_defined>")
	out_lex_cls_events_memb()
	out_line("// </lex_usr_defined>")
	out_line()
	
	out_line("// read the next character, advance the input")
	out_line(sprintf("static inline int %s(%s * lex)",
		N_LEX_READ_CH(), N_LEX_STATE()))
	out_line("{")
	tabs_inc()
	out_line("lex->curr_ch = *lex->input++;")
	out_line("++lex->input_pos;")
	out_line("if (!(*lex->input))")
	tabs_inc()
	out_line(sprintf("lex->input = %s(lex->usr_arg);", N_LEX_USR_GET_INPUT()))
	tabs_dec()
	out_line("return lex->curr_ch;")
	tabs_dec()
	out_line("}")

	out_line()
	out_line("// look at, but do not read, the next character")
	out_line(sprintf("static inline int %s(%s * lex)",
		N_LEX_PEEK_CH(), N_LEX_STATE()))
	out_line("{return *lex->input;}")
	out_line()
	out_line("// call this before writing to the lexer write space")
	out_line(sprintf("static inline void %s(%s * lex)",
		N_LEX_SAVE_BEGIN(), N_LEX_STATE()))
	out_line("{lex->write_buff_pos = 0;}")
	out_line()

	out_line("// call this to write to the lexer write space")
	out_line(sprintf("static inline bool %s(%s * lex)",
		N_LEX_SAVE_CH(), N_LEX_STATE()))
	out_line("{")
	tabs_inc()
	out_line("bool is_saved = (lex->write_buff_pos < lex->write_buff_len);") 
	out_line("if (is_saved)")
	tabs_inc()
	out_line("lex->write_buff[lex->write_buff_pos++] = lex->curr_ch;")
	tabs_dec()
	out_line("return is_saved;")
	tabs_dec()
	out_line("}")
	
	out_line()
	out_line("// call this after you're done writing to the lexer write space")
	out_line(sprintf("static inline void %s(%s * lex)",
		N_LEX_SAVE_END(), N_LEX_STATE()))
	out_line("{lex->write_buff[lex->write_buff_pos] = '\\0';}")
	out_line()
	out_line("// get what you've written")
	out_line(sprintf("static inline char * %s(%s * lex)",
		N_LEX_GET_SAVED(), N_LEX_STATE()))
	out_line("{return lex->write_buff;}")
	out_line()
	out_line("// see how long it is")
	out_line(sprintf("static inline uint %s(%s * lex)",
		N_LEX_GET_SAVED_LEN(), N_LEX_STATE()))
	out_line("{return lex->write_buff_pos;}")
	out_line()
	out_line("// so it's possible for the user to access their argument back")
	out_line(sprintf("static inline void * %s(%s * lex)",
		N_LEX_GET_USR_ARG(), N_LEX_STATE()))
	out_line("{return lex->usr_arg;}")
	out_line()
	out_line("// get the character position on the current input line")
	out_line(sprintf("static inline uint %s(%s * lex)",
		N_LEX_GET_INPUT_POS(), N_LEX_STATE()))
	out_line("{return lex->input_pos;}")
	out_line()
	out_line("// get the number of the current input line")
	out_line(sprintf("static inline uint %s(%s * lex)",
		N_LEX_GET_INPUT_LINE_NO(), N_LEX_STATE()))
	out_line("{return lex->input_line;}")
	out_line()
	out_line("// get the last character the lexer read")
	out_line(sprintf("static inline int %s(%s * lex)",
		N_LEX_GET_CURR_CH(), N_LEX_STATE()))
	out_line("{return lex->curr_ch;}")
	out_line()
	out_line("// get the last token the lexer read")
	out_line(sprintf("static inline %s %s(%s * lex)",
		N_TOK_ID(), N_LEX_GET_CURR_TOK(), N_LEX_STATE()))
	out_line("{return lex->curr_tok;}")
	out_line()
	out_line("// see if tok is the same as the token in the lexer")
	out_line(sprintf("static inline bool %s(%s * lex, %s tok)",
		N_LEX_MATCH(), N_LEX_STATE(), N_TOK_ID()))
	out_line("{return (lex->curr_tok == tok);}")
	out_line()
	
	out_line(sprintf("static inline void %s(%s * lex, %s * init)",
		N_LEX_INIT(), N_LEX_STATE(), N_LEX_INIT_INFO()))
	out_line("{")
	tabs_inc()
	out_line(sprintf("lex->input = %s(init->usr_arg);", N_LEX_USR_GET_INPUT()))
	out_line("lex->input_pos = 0;")
	out_line("lex->curr_ch = -1;")
	out_line(sprintf("lex->curr_tok = %s;", TOK_ERR_ENUM()))
	out_line("lex->input_line = 1;")
	out_line("lex->usr_arg = init->usr_arg;")
	out_line("lex->write_buff = init->write_buff;")
	out_line("lex->write_buff_len = init->write_buff_len;")
	out_line("lex->write_buff_pos = 0;")
	tabs_dec()
	out_line("}")

	out_line()
	out_line("// returns the string representation of tok")
	out_line(sprintf("const char * %s(%s tok);",
		N_LEX_TOK_TO_STR(), N_TOK_ID()))
	out_line()
	out_line("// reads and returns the next token from the input")
	out_line(sprintf("%s %s(%s * lex);",
		N_TOK_ID(), N_LEX_NEXT(), N_LEX_STATE()))
	out_line()
	if (has_keywords()) {
		out_line("// returns the token for the keyword in lex's write buffer, "\
			"or base if not a")
		out_line(sprintf("// keyword; lookup method: %s", get_kw_type()))
		out_line(sprintf("%s;", IS_KW_HEAD()))
	}
}
function out_tok_enum(    _set, _set_const, _set_str, _i, _end, _line_len, _j) {
	lb_vect_make_set(_set, G_symbols_vect, 2)
	lb_vect_copy(_set_const, _set)
	lb_vect_make_set(_set, G_keywords_vect, 2)
	lb_vect_append(_set_const, _set)
	lb_vect_make_set(_set, G_patterns_vect, 2)
	lb_vect_append(_set_const, _set)

	lb_vect_make_set(_set, G_symbols_vect, 1)
	lb_vect_copy(_set_str, _set)
	lb_vect_make_set(_set, G_keywords_vect, 1)
	lb_vect_append(_set_str, _set)
	lb_vect_make_set(_set, G_patterns_vect, 1)
	lb_vect_append(_set_str, _set)
	
	out_line(sprintf("typedef enum %s {", N_TOK_ID()))

	# Print _line_len enum values per line.
	_line_len = 4
	_i = 1
	_end = vect_len(_set_const)
	
	while (_i <= _end) {

		# Print the token value enum constant name.
		for (_j = 0; _j < _line_len && _i+_j <= _end; ++_j) 
			printf("%-20s", sprintf("%s,", _set_const[_i+_j]))
		out_line()

		# Print the token string as a comment below.
		for (_j = 0; _j < _line_len && _i+_j <= _end; ++_j)
			printf("%-20s", sprintf("/* \"%s\" */", _set_str[_i+_j]))
		out_line()

		_i += _j
		
	}
	
	out_line(sprintf("%s," , TOK_ERR_ENUM()))
	out_line(sprintf("/* \"%s\" */", TOK_ERR_STR()))

	out_line(sprintf("} %s;", N_TOK_ID()))
}
# </out_header>

# <out_source>
function out_source() {
	out_line("// <lex_source>")
	out_signature()
	out_line(sprintf("#include \"%s\"", npref("lex.h")))

	if (get_kw_type() != KW_IFS()) {
		out_line("#include <string.h>")
		out_line("#include <stdlib.h>")
	}
	
	out_line()
	out_tok_tbl()
	out_line()
	out_tok_to_str()
	out_line()
	out_all_char_tbl()
	out_line()
	out_keywords()
	out_line("// </lex_source>")
}
# <tok_tbl>
function TOK_ERR_STR() {return "I am Error"}
function TOK_ERR_ENUM() {return (toupper(npref_get()) "TOK_ERROR")}
function out_tok_tbl(    _set, _set_str, _set_const, _i, _end, _line_len, _j) {
	lb_vect_make_set(_set, G_symbols_vect, 1)
	lb_vect_copy(_set_str, _set)
	lb_vect_make_set(_set, G_keywords_vect, 1)
	lb_vect_append(_set_str, _set)
	lb_vect_make_set(_set, G_patterns_vect, 1)
	lb_vect_append(_set_str, _set)

	lb_vect_make_set(_set, G_symbols_vect, 2)
	lb_vect_copy(_set_const, _set)
	lb_vect_make_set(_set, G_keywords_vect, 2)
	lb_vect_append(_set_const, _set)
	lb_vect_make_set(_set, G_patterns_vect, 2)
	lb_vect_append(_set_const, _set)

	
	# Print all tokens in a static string table.
	out_line("static const char * tokens[] = {")

	# Print _line_len tokens per line.
	_line_len = 4
	_i = 1
	_end = vect_len(_set_str)
	while (_i <= _end) {

		# Print the token string representation.
		for (_j = 0; _j < _line_len && _i+_j <= _end; ++_j) 
			printf("%-20s", sprintf("\"%s\",", _set_str[_i+_j]))
		out_line()

		# Print the name of its enum constant as a comment below.
		for (_j = 0; _j < _line_len && _i+_j <= _end; ++_j)
			printf("%-20s", sprintf("/* %s */", _set_const[_i+_j]))		
		out_line()
		
		_i += _j
	}
	
	out_line(sprintf("\"%s\"," , TOK_ERR_STR()))
	out_line(sprintf("/* %s */", TOK_ERR_ENUM()))
	
	out_line("};")

}
# </tok_tbl>
# <lex_tok_to_str>
function out_tok_to_str() {
	out_line(sprintf("const char * %s(%s tok)",
		N_LEX_TOK_TO_STR(), N_TOK_ID()))
	out_line("{")
	tabs_inc()
	out_line("return tokens[tok];")
	tabs_dec()
	out_line("}")
}
# </lex_tok_to_str>
# <char_tbls>
function out_all_char_tbl() {
	out_ch_cls_enum()
	out_line()
	out_char_tbl()
	out_line()
	out_lex_next()
}
function out_ch_cls_enum(    _i, _end, _cls_set, _line_len) {
	lb_vect_make_set(_cls_set, G_char_tbl_vect, 2)

	out_line(sprintf("enum %s {", N_CHAR_CLS()))
	
	_line_len = 4
	_i = 1
	_end = vect_len(_cls_set)
	
	while (_i <= _end) {
	
		for (_j = 0; _j < _line_len && _i+_j <= _end; ++_j) {
			if ((_i+_j) == 1)
				printf("%-20s", sprintf("%s = 1,", _cls_set[_i+_j]))
			else
				printf("%-20s", sprintf("%s,", _cls_set[_i+_j]))
		}
		out_line()
		
		_i += _j
	}
	
	out_line("};")
}
function out_char_tbl(    _i, _end, _ch, _str, _map_ch_cls,
_zero_line_len, _zero_new_line, _j, _ch_out) {
	out_line("#define CHAR_TBL_SZ (0xFF+1)")
	out_line("typedef unsigned char byte;")

	# Print a static constant table for the character classes.
	# Prints at most 16 zeroes, or two char classes along with their values as
	# comments per line.
	out_line("static const byte char_cls_tbl[CHAR_TBL_SZ] = {")

	lb_vect_to_map(_map_ch_cls, G_char_tbl_vect)

	_zero_new_line = 0
	_zero_line_len = 16

	_i = 0
	_end = CHR_TBL_END()
	while (_i < _end) {
		_j = 0
		do {
			_ch = num_to_ch(_i)

			if (" " == _ch)
				_ch = CH_ESC_SPACE()

			_zero_new_line = 0
			if (!(_ch in _map_ch_cls)) {

				if (_ch_out) {
					out_line()
					_ch_out = 0
				}
				
				if (!(_j % _zero_line_len))
					out_tabs()

				printf("0, ")

				if ((_j % _zero_line_len) == (_zero_line_len - 1)) {
					out_line()
					_zero_new_line = 1
				}
				
				++_j
				++_i
			}
		} while (!(_ch in _map_ch_cls) && _i < _end)

		if (_j && !_zero_new_line)
			out_line()
		
		if (!(_i < _end))
			break

		if ("\\" == _ch)
			_str = "\\\\"
		else if (CH_ESC_SPACE() == _ch)
			_str = " "
		else
			_str = _ch
	
		printf("%-35s ",
			sprintf("/* %03d 0x%02X '%s' */ %s,",
				_i, _i, _str, _map_ch_cls[_ch]))
		
		++_ch_out
		if (2 == _ch_out) {
			out_line()
			_ch_out = 0
		}
		
		++_i
	}
		
	out_line("};")
	
	out_line("#define char_cls_get(ch) ((byte)char_cls_tbl[(byte)(ch)])")
}

function out_kw_const() {
	out_line(sprintf("#define KW_LONG  %d // longest keyword length",
		kw_longest()))
	out_valid_len()
}
# </char_tbls>
function CHR_TBL_END() {return 128}
# <lex_next>
function out_tree_symb(tree, root, map_tok,    _next_str, _next_ch, _i, _end) {
	# E.g. "=", "==", "=!" becomes
	# if ('=' == next_ch()) {
	#     tok = "="
	#     read_ch()
	#     if ('=' == next_ch()) {
	#         tok = "=="
	#         read_ch()
	#      } else if ('!' == next_ch()) {
	#         tok = "=!"
	#         read_ch()
	#      }
	# }
	
	if (ch_ptree_has(tree, root) || ch_ptree_is_word(tree, root)) {

		if (ch_ptree_is_word(tree, root))
			out_line(sprintf("tok = %s;", map_tok[root]))
			
		_next_str = ch_ptree_get(tree, root)
		_end = length(_next_str)
		for (_i = 1; _i <= _end; ++_i) {
			_next_ch = str_ch_at(_next_str, _i)

			if (_end > 1) {
				# If more than one call to lex_peek_ch() is needed, cache the
				# result into peek_ch.
				
				if (1 == _i)
					out_line(sprintf("peek_ch = %s(lex);", N_LEX_PEEK_CH()))
			
				out_line(sprintf("%s ('%s' == peek_ch)",
					(_i == 1) ? "if" : "else if" ,_next_ch))
			} else {
				# Do not cache for only a single call.
				
				out_line(sprintf("%s ('%s' == %s(lex))",
					(_i == 1) ? "if" : "else if" ,_next_ch, N_LEX_PEEK_CH()))
			}
			
			out_line("{")
			tabs_inc()
			out_line(sprintf("%s(lex);", N_LEX_READ_CH()))
			out_tree_symb(tree, (root _next_ch), map_tok)

			tabs_dec()
			out_line("}")
		}
	}
}
function out_lex_next(    _i, _end, _cls_set, _cls, _act, _map_cls_chr,
_map_symb, _map_act, _tree, _tmp, _dont_go) {

	# Generates lex_next(), which is a big switch statement which switches on
	# the class of the current character. The class values are contiguous, so
	# it's easy for a compiler to turn the switch into a jump table. The class
	# of the character is derived by a quick table lookup, e.g. ch_cls[curr_ch]
	# In each case, either a token is found, a user callback is called, or some
	# custom to the lexer action is performed. E.g.:
	# ...
	# case CH_GT: /* '>' */
	#     tok = TOK_GT;
	#     if (next_ch() == '=')
	#         tok = TOK_GEQ;
	# ...
	# case CH_WORD: // a-z A-Z _
	#     tok = usr_defined_get_kword()
	# ...
	# case CH_NEW_LINE:
	#     ++lex->line_no;
	# ...
	
	lb_vect_make_set(_cls_set, G_char_tbl_vect, 2)
	
	out_line(sprintf("%s %s(%s * lex)",
		N_TOK_ID(), N_LEX_NEXT(), N_LEX_STATE()))
	out_line("{")
	tabs_inc()

	out_line("int peek_ch = 0;")
	out_line(sprintf("%s tok = %s;", N_TOK_ID(), TOK_ERR_ENUM()))
	out_line("while (true)")
	out_line("{")
	tabs_inc()
	
	out_line(sprintf("switch (char_cls_get(%s(lex)))", N_LEX_READ_CH()))
	out_line("{")
	tabs_inc()

	lb_vect_to_map(_map_cls_chr, G_char_tbl_vect, 2, 1)
	lb_vect_to_map(_map_symb, G_symbols_vect)
	lb_vect_to_map(_map_act, G_actions_vect)
	ch_ptree_init(_tree)

	for (_tmp in _map_symb) {
		# Constants are not symbol tokens. I.e. EOI (end of input) can exist in
		# the symbol table, but the character sequence E O I is not a token in
		# the sense in which "==" is for example, so don't put it in the tree
		# with the other tokens.
		
		if (!is_constant(_tmp))
			ch_ptree_insert(_tree, _tmp)
	}

	_end = vect_len(_cls_set)
	for (_i = 1; _i <= _end; ++_i) {
		_cls = _cls_set[_i]
		_dont_go = 0 # <-- stays 0 if a complete token was read

		if (match(_cls, CH_CLS_AUTO_RE()))
			out_line(sprintf("case %s: /* '%s' */", _cls, _map_cls_chr[_cls]))
		else
			out_line(sprintf("case %s:", _cls))
		
		out_line("{")
		tabs_inc()
		
		if (_cls in _map_act) {
			_act = _map_act[_cls]
			if (match(_act, FCALL())) {
				# If the action ends in (), then it's a user defined callback,
				# which has to take lex as an argument.
				
				sub(FCALL(), "(lex)", _act)
				out_line(sprintf("tok = %s;", npref("lex_usr_" _act)))
			} else if (NEXT_CH() == _act) {
				# Immediately jump back to the top of the loop on white space.
				
				_dont_go = 1
				out_line("continue;")
			} else if (NEXT_LINE() == _act) {
				# Count lines.
				
				out_line("++lex->input_line;")
				out_line("lex->input_pos = 0;")
				out_line("continue;")
				_dont_go = 1
			} else if (is_constant(_act)) {
				# Constants are assumed to be meaningful token enums.
				
				out_line(sprintf("tok = %s;", _act))
			} else {
				# Should never happen.
				
				out_line("#error \"unknown action\"")
			}
		} else {
			# Generate if trees for all tokens which begin with the current
			# character class and are longer than a single character. The
			# character class is assumed to represent only a single character.
			
			_tmp = _map_cls_chr[_cls]
			if (length(_tmp) == 1)
				out_tree_symb(_tree, _tmp, _map_symb)
		}

		if (!_dont_go)
			out_line("goto done;")
			
		tabs_dec()
		out_line("} break;")
	}
	out_line("default:")
	out_line("{")
	tabs_inc()
	
	# Called on weird input, e.g. an '@' character in a C file.
	out_line(sprintf("tok = %s(lex);", N_LEX_USR_ON_UNKNOWN_CH()))
	out_line("goto done;")
	tabs_dec()
	out_line("} break;")
		
	tabs_dec()
	out_line("}")
	tabs_dec()
	out_line("}")

	print "done:"
	out_line("return (lex->curr_tok = tok);")
	tabs_dec()
	out_line("}")
}
# </lex_next>
# <keywords>
function kw_longest(    _set, _i, _end, _max, _n) {
	lb_vect_make_set(_set, G_keywords_vect)

	_max = length(_set[1])
	_end = vect_len(_set)
	for (_i = 2; _i <= _end; ++_i) {
		_n = length(_set[_i])
		if (_n > _max)
			_max = _n
	}
	
	return _max
}

function has_keywords() {return vect_len(G_keywords_vect)}
function set_kw_type(str) {_B_kw_type = str}
function get_kw_type() {return _B_kw_type}

function out_keywords() {
	if (has_keywords()) {
		out_line("// <lex_keyword_or_base>")

		out_kw_const()
		
		out_line()
		
		if (get_kw_type() == KW_BSEARCH())
			out_kw_bsrch()
		else if (get_kw_type() == KW_IFS())
			out_kw_ifs()

		out_line("// </lex_keyword_or_base>")
	}
}
function IS_KW_HEAD() {
	return sprintf("%s %s(%s * lex, %s base)",
		N_TOK_ID(), N_LEX_KEYWORD_OR_BASE(), N_LEX_STATE(), N_TOK_ID())
}
function out_is_kw_head() {out_line(IS_KW_HEAD())}
function KW_LEN_LIMIT() {return 31}
function out_valid_len(    _i, _end, _j, _jend, _valid_lengths, _bin_str, _add,
_kw_set, _kw_lengths) {
	# Generate a bitmap of valid keyword lengths. Bit number 0 is always 0. If
	# there are keywords with a length of 1, then bit number 1 is 1, if not,
	# then it's 0. If there are keywords 2 characters long, then bit 2 is 1, 0
	# if there aren't, etc. You can then easily check if a keyword of length
	# n exists by (VALID_LENGTHS & (1 << n)), given n <= 31.


	lb_vect_make_set(_kw_set, G_keywords_vect, 1)

	_end = vect_len(_kw_set)
	for (_i = 1; _i <= _end; ++_i)
		_kw_lengths[_i] = length(_kw_set[_i])
	
	_end = KW_LEN_LIMIT()
	_jend = vect_len(_kw_set)

	# Get the actual int value of the bit map and generate as binary
	_bin_str = "0"
	_valid_lengths = 0
	for (_i = 1; _i <= _end; ++_i) {
		_add = "0"
		for (_j = 1; _j <= _jend; ++_j) {
			if (_i == _kw_lengths[_j]) {
				_valid_lengths = or(_valid_lengths, lshift(1, _i))
				_add = "1"
				break
			}	
		}

		if (!(_i % 8))
			_bin_str = (" " _bin_str)
		else if (!(_i % 4))
			_bin_str = ("_" _bin_str)
			
		_bin_str = (_add _bin_str)
	}

	out_line(sprintf("#define VALID_LENGTHS 0x%08XU // %s",
		_valid_lengths, _bin_str))
	out_line("#define is_valid_len(len) (VALID_LENGTHS & (1 << (len)))")
}

function KW_LEN_CHECK() {
	return "txt_len <= KW_LONG && is_valid_len(txt_len)"
}

# <lex_kw_lookup_bsearch>
function out_kw_static_tbls(    _set, _sorted, _i, _end, _pad, _map_kw, _tbl,
_start, _len, _ch, _nout) {
	lb_vect_make_set(_set, G_keywords_vect, 1)
	lb_vect_to_map(_map_kw, G_keywords_vect)
	lb_vect_to_array(_sorted, _set)
	
	_end = asort(_sorted)

	# Output keywords table
	out_line("// sorted; don't jumble up")
	out_line(sprintf("static const char * kws[%d] = {", _end))
	out_tabs()
	_pad = 4
	for (_i = 1; _i <= _end; ++_i) {
		printf("%-15s", sprintf("\"%s\", ", _sorted[_i]))
		if (!(_i % _pad) && _i != _end) {
			out_line()
			out_tabs()
		}
	}
	out_line()
	out_line("};")

	out_line()
	# Output tokens table
	out_line(sprintf("static const %s tks[%d] = {", N_TOK_ID(), _end))
	out_tabs()
	for (_i = 1; _i <= _end; ++_i) {
		printf("%-15s", sprintf("%s, ", _map_kw[_sorted[_i]]))
		if (!(_i % _pad) && _i != _end) {
			out_line()
			out_tabs()
		}
	}
	out_line()
	out_line("};")

	out_line()
	out_line("typedef struct kw_len_data {")
	tabs_inc()
	out_line("byte start;")
	out_line("byte len;")
	tabs_dec()
	out_line("} kw_len_data;")

	# Find out keyword len info by first character
	# _end is still the length of _sorted
	for (_i = 1; _i <= _end; ++_i)
		++_tbl[str_ch_at(_sorted[_i], 1)]

	# Sort only the first characters of all keywords in _sorted
	_end = asorti(_tbl, _sorted)

	out_line()
	# Output the len data per first character
	out_line(sprintf("static const kw_len_data kwlen[CHAR_TBL_SZ] = {", _end))
	out_tabs()

	# Start index of words starting with a particular character in kws
	_start = 0
	# The number of words which start with a particular character
	_len = 0
	# Count of how many empty structs have been output so some formatting exists
	_nout = 0
	_pad = 8
	
	_end = CHR_TBL_END()
	for (_i = 0; _i < _end; ++_i) {
		_ch = num_to_ch(_i) 
		if ((_ch in _tbl)) {
			# Print the struct for a particular character and reset the counter
			# for empty structs
			_len = _tbl[_ch]

			# Ugly 'make sure you don't output two new lines after each other'
			if (_nout % _pad) {
				out_line()
				out_tabs()
			}

			printf("{%d, %d}, /* '%s' */", _start, _len, _ch)
			out_line()
			out_tabs()
			_start += _len
			_nout = 0
		} else {
			# Print at most _pad empty structs on a line
			printf("{0, 0}, ")
			++_nout
			if ((_i+1 < _end) && !(_nout % _pad)) {
				out_line()
				out_tabs()
			}
		}
	}
	out_line()
	out_line("};")
}
function out_bsrch_prereq() {
	out_line("static int compar(const void * a, const void * b)")
	out_line("{")
	tabs_inc()
	out_line("const char * key = (const char *)a;")
	out_line("const char * str = *(const char **)b;")
	out_line("return strcmp(key, str);")
	tabs_dec()
	out_line("}")
}
function out_kw_bsrch() {
	out_bsrch_prereq()
	out_line()
	out_is_kw_head()
	out_line("{")
	tabs_inc()

	out_kw_static_tbls()
	out_line()
	
	out_line(sprintf("%s tok = base;", N_TOK_ID()))
	out_line("const char * txt = lex->write_buff;")
	out_line("byte first = (byte)*txt;")
	out_line("uint start = kwlen[first].start;")
	out_line("uint len = kwlen[first].len;")
	out_line("uint txt_len = lex->write_buff_pos;")
	
	# Call bsearch() only if a keyword with length(input) exists and limit the
	# search to the range of keywords with exactly that length.
	out_line()
	out_line(sprintf("if (!(%s && len))", KW_LEN_CHECK()))
	tabs_inc()
	out_line("return tok;")
	tabs_dec()

	out_line()
	out_line("const char ** kw = (const char **)bsearch(txt,")
	tabs_inc()
	out_line("kws+start,")
	out_line("len,")
	out_line("sizeof(*kws),")
	out_line("compar")
	tabs_dec()
	out_line(");")

	out_line()
	out_line("return ((!kw) ? tok : tks[kw-kws]);")

	tabs_dec()
	out_line("}")
}
# </lex_kw_lookup_bsearch>

# # <lex_kw_lookup_ifs>
function out_kw_walk(tree, root, map_kw, n,    _next, _ch, _i, _end) {

	if (ch_ptree_has(tree, root) || ch_ptree_is_word(tree, root)) {
	
		_ch = str_ch_at(root, length(root))
		out_line(sprintf("%s ('%s' == *ch)", (1 == n) ? "if" : "else if", _ch))
		out_line("{")
		tabs_inc()
		out_line("++ch;")

		if (ch_ptree_is_word(tree, root))
			out_line(sprintf("tok = %s;", map_kw[root]))
		
		_next = ch_ptree_get(tree, root)
		_end = length(_next)
		for (_i = 1; _i <= _end; ++_i)
			out_kw_walk(tree, (root str_ch_at(_next, _i)), map_kw, _i)
			
		tabs_dec()
		out_line("}")
	}
}
function out_kw_ifs(    _tree, _set_kw, _map_kw, _i, _end, _vect, _set_ch) {

	# Find out if, and which, keyword the input is by literal if statements for
	# each character.

	lb_vect_make_set(_set_kw, G_keywords_vect, 1)
	lb_vect_to_map(_map_kw, G_keywords_vect)
	ch_ptree_init(_tree)
	
	_end = vect_len(_set_kw)
	for (_i = 1; _i <= _end; ++_i) {
		ch_ptree_insert(_tree, _set_kw[_i])
		vect_push(_vect, str_ch_at(_set_kw[_i], 1))
	}
	lb_vect_make_set(_set_ch, _vect)

	out_is_kw_head()
	out_line("{")
	tabs_inc()
	out_line(sprintf("%s tok = base;", N_TOK_ID()))
	out_line("uint txt_len = lex->write_buff_pos;")
	out_line()

	# Do not proceed if there are no keywords with length(input)
	out_line(sprintf("if (!(%s))", KW_LEN_CHECK()))
	tabs_inc()
	out_line("return tok;")
	tabs_dec()
	
	out_line()
	out_line("const char * ch = lex->write_buff;")
	
	_end = vect_len(_set_ch)
	# Generate one big if - else if tree for all keywords.
	for (_i = 1; _i <= _end; ++_i)
		out_kw_walk(_tree, _set_ch[_i], _map_kw, _i)
	out_line()

	# Whatever the value of 'tok' is at this point, it is valid if and only if
	# '*ch' is at the end of the input. This ensures the longest possible match.
	# E.g. if the input is "dont" and "do" is a keyword, at this point 'tok'
	# would have the value of TOK_DO, given another keyword of length 4 exists.
	# This is not correct, as "do" is a prefix of "dont", so to be sure 'tok' is
	# actually the "do" keyword, '*ch' has to be at the end of the string.
	
	out_line("return ('\\0' == *ch) ? tok : base;")
	tabs_dec()
	out_line("}")
}
# </lex_kw_lookup_ifs>
# </keywords>
# </out_source>

# <misc>
function generate() {
	out_header()
	out_source()
}
function KW_BSEARCH() {return "bsearch"}
function KW_IFS() {return "ifs"}
function check_kw_lookup_type(str) {
	if (str != KW_BSEARCH() && str != KW_IFS()) {
		err_quit(sprintf("Keywords has to be one of: %s, %s",
			KW_BSEARCH(), KW_IFS()))
	}
}
function kw_len_check(    _kw_set) {
	lb_vect_make_set(_kw_set, G_keywords_vect, 1)

	_end = vect_len(_kw_set)
	for (_i = 1; _i <= _end; ++_i) {
		if (length(_kw_set[_i]) > KW_LEN_LIMIT()) {
			# We have a limit because an int bitmap is used to check if a
			# keyword of a certain length exists.
	
			err_quit(sprintf("keyword '%s': length cannot be greater than %d",
				_kw_set[_i], KW_LEN_LIMIT()))
		}
	}
}
function npref(str) {return (npref_get() str)}
function npref_set(str) {_B_npref = str}
function npref_get() {return _B_npref}
function npref_constants_all() {
	npref_constants(G_char_tbl_vect, 2, npref_get())
	npref_constants(G_symbols_vect, 2, npref_get())
	npref_constants(G_keywords_vect, 2, npref_get())
	npref_constants(G_patterns_vect, 2, npref_get())
	npref_constants(G_actions_vect, 1, npref_get())
	npref_constants(G_actions_vect, 2, npref_get())
}

function err_quit(msg) {
	error_quit(msg, SCRIPT_NAME())
}

function on_help() {
print sprintf("%s -- lex-build C back end", SCRIPT_NAME())
print ""
print "Static inline functions are preferred over macros, hence compiling with"
print "optimizations would make a significant difference. The user implements"
print "lex_usr_*()"
print ""
print "Options:"
print sprintf("-vKeywords=%s/%s - specifies the keyword lookup method.",
	KW_BSEARCH(), KW_IFS())
print sprintf("%s - optimized binary search; generally <= work compared to " \
"hashing.", KW_BSEARCH())
print sprintf("%s     - a literal character by character if - else if tree. " \
"Generally linear.", KW_IFS())
print sprintf("Faster than %s, doesn't use stdlib.h and string.h, but more " \
"code. %s", KW_BSEARCH(), KW_BSEARCH())
print "is the default."
print "-vNamePrefix=<string> - prefixes all function and constant names with "\
"<string>."
print "E.g. -vNamePrefix='foo_' will result in foo_lex_usr_get_input()"
print ""
}

function on_version() {
print sprintf("%s %s", SCRIPT_NAME(), SCRIPT_VERSION())
}

function on_begin() {
	lex_lib_is_included()
	
	vect_init(G_char_tbl_vect)
	vect_init(G_symbols_vect)
	vect_init(G_keywords_vect)
	vect_init(G_patterns_vect)
	vect_init(G_actions_vect)
	
	if (!Keywords)
		Keywords = KW_BSEARCH()
	check_kw_lookup_type(Keywords)
	set_kw_type(Keywords)
	
	npref_set(NamePrefix)
}
function on_char_tbl() {save_to(G_char_tbl_vect)}
function on_symbols()  {save_to(G_symbols_vect)}
function on_keywords() {save_to(G_keywords_vect)}
function on_patterns() {save_to(G_patterns_vect)}
function on_actions()  {save_to(G_actions_vect)}
function on_end()      {kw_len_check(); npref_constants_all(); generate()}

# Produce an error if lex_lib.awk is not included
BEGIN {lex_lib_is_included()}
# </misc>
# <lb_common>
# Common lex-build functionality
# v1.11

# Author: Vladimir Dinev
# vld.dinev@gmail.com
# 2021-10-17

# <misc>
function join(a, b) {return (a SUBSEP b)}
function unjoin(arr_out, str) {return split(str, arr_out, SUBSEP)}
function save_to(vect) {
	# Usually called from user handlers. Makes sure you don't save delimiters.
	if (!is_range_word($0))
		vect_push(vect, join($1, $2))
}
function out_line(str) {if (str) tabs_print_str(str); print ""}
function out_str(str) {tabs_print_str(str)}
function out_tabs() {printf("%s", tabs_get())}

function str_up_to(str, pos) {return substr(str, 1, pos)}
function str_ch_at(str, pos) {return substr(str, pos, 1)}
function str_has_ch(str, ch) {return index(str, substr(ch, 1, 1))}
# </misc>

# <lb_vect>
function lb_vect_copy(vect_dest, vect_src) {
	vect_init_arr(vect_dest, vect_src, vect_len(vect_src))
}
function lb_vect_append(vect_dest, vect_src) {
	vect_push_arr(vect_dest, vect_src, vect_len(vect_src))
}
function lb_vect_to_array(arr_dest, vect_src) {
	return arr_copy(arr_dest, vect_src, vect_len(vect_src))
}
function lb_vect_make_set(set_out, vect_in, fld,    _i, _end, _split) {
	if (!fld)
		fld = 1
	
	eos_init(set_out)
	_end = vect_len(vect_in)
	for (_i = 1; _i <= _end; ++_i) {
		unjoin(_split, vect_in[_i])
		eos_add(set_out, _split[fld])
	}
}
function lb_vect_to_map(map_out, vect_in, field_ind, field_val,
    _i, _end, _arr) {
	# Turn vect[1] = ("foo" SUBSEP "bar") into vect["foo"] = "bar", or
	# vect["bar"] = "foo". Repeat for all items of vect.

	delete map_out
	if (!field_ind) {
		field_ind = 1
		field_val = 2
	}
	
	_end = vect_len(vect_in)
	for (_i = 1; _i <= _end; ++_i) {
		unjoin(_arr, vect_in[_i])
		map_out[_arr[field_ind]] = _arr[field_val] 
	}
}
# <lb_vect>

# <ch_pref_tree>
# This is a prefix tree. Turns e.g. "this", "that" into
# tree["t"] = "h"
# tree["th"] = "ia"
# tree["thi"] = "s"
# tree["tha"] = "t"
# Used to generate the if trees for multi character tokens and for keyword
# recognition.

function ch_ptree_init(tree) {pft_init(tree)}
function _ch_ptree_mark_word(tree, str) {pft_mark(tree, str)}
function _ch_ptree_insert(tree, str,    _arr, _len) {
	_len = split(str, _arr, "")
	pft_insert(tree, pft_arr_to_pft_str(_arr, _len))
}
function ch_ptree_has(tree, str,    _arr, _len) {
	_len = split(str, _arr, "")
	return pft_has(tree, pft_arr_to_pft_str(_arr, _len))
}
function ch_ptree_is_word(tree, str) {
	return pft_is_marked(tree, str)
}
function ch_ptree_insert(tree, str) {
	if (!ch_ptree_is_word(tree, str)) {
		_ch_ptree_mark_word(tree, str)
		_ch_ptree_insert(tree, str)
	}
}
function ch_ptree_get(tree, ind,    _arr, _len) {
	_len = split(ind, _arr, "")
	_str = pft_get(tree, pft_arr_to_pft_str(_arr, _len))
	gsub(PFT_SEP(), "", _str)
	return _str
}
# </ch_pref_tree>

# <lex_constants>
# The constants used to generate and recognize automatically generated character
# classes.
function CH_CLS_AUTO_GEN() {return "CH_CLS_AUTO_%d_"}
function CH_CLS_AUTO_RE() {return "CH_CLS_AUTO_[0-9]+_"}

# Special actions. They can be values in the 'actions' table and their meaning
# is determined by the writer of the lex-*.awk in accordance with its target
# language.
function NEXT_CH() {return "next_ch"}
function NEXT_LINE() {return "next_line"}

# Since a space character cannot exist literally in the input, it has to be
# represented by an escape sequence.
function CH_ESC_SPACE() {return "\\s"}

# Use to check if an actions looks like a function call.
function FCALL() {return "\\(\\)$"}
# </lex_constants>

# <base>
# This is where the actual awk loop comes from for all lex-*.awk

function is_constant(str) {
	# Checks for the usual C I_AM_C0NST4NT syntax. Constants are intended to be
	# ignored by the general generation process, e.g. they do not get inserted
	# into prefix trees, and are left for the lex-*.awk writer to handle. E.g.
	# you may want to have a token symbol for EOI (end of input), which would
	# probably be the empty string and not the character sequence E O I. So you
	# can have EOI as a symbol and pick it out form the rest with this function.
	return match(str, "^[[:upper:]_[:digit:]]+$")
}

function is_range_word(str) {
	# Used to separate the input delimiters from the actual input.	
	return (END_() == str || CHAR_TBL() == str || SYMBOLS() == str ||
	KEYWORDS() == str || PATTERNS() == str || ACTIONS() == str) 
}

function npref_constants(vect, ind, pref,    _i, _end, _arr, _str) {
# Call this to prefix all constants saved in vect. Note that 'ind' is the index
# in the sub array, as per the usual save_to(), join(), unjoin() structure.

	if (ind != 1 && ind != 2)
		return

	pref = toupper(pref)

	_end = vect_len(vect)
	for (_i = 1; _i <= _end; ++_i) {
		_str = vect[_i]

		unjoin(_arr, _str)
		if (is_constant(_arr[ind]))
			_arr[ind] = (pref _arr[ind])

		vect[_i] = join(_arr[1], _arr[2])
	}
}

# The input delimiters.
function END_()     {return "end"}
function CHAR_TBL() {return "char_tbl"}
function SYMBOLS()  {return "symbols"}
function KEYWORDS() {return "keywords"}
function PATTERNS() {return "patterns"}
function ACTIONS()  {return "actions"}

# Main awk loop. on_*() are defined by the user. From the user's standpoint
# parsing is event driven.

function quit_ok() {
	skip_end_set()
	exit_success()
}

function lib_init() {
	ch_num_init()
	set_program_name(SCRIPT_NAME())
	if (Help) {
		on_help()
		print_help_common()
		quit_ok()
	}
	if (Version) {
		on_version()
		quit_ok()
	}
}

function print_help_common() {
print "-vVersion=1 - print version info"
print "-vHelp=1    - print this screen"
}

function on_else() {err_quit(sprintf("'%s' unknown", $0))}

# Call this in on_begin(); produces an error if lex_lib.awk is not included.
function lex_lib_is_included() {}

BEGIN {lib_init(); on_begin()}
$0 == CHAR_TBL(), $0 == END_() {on_char_tbl(); next}
$0 == SYMBOLS(), $0 == END_()  {on_symbols(); next}
$0 == KEYWORDS(), $0 == END_() {on_keywords(); next}
$0 == PATTERNS(), $0 == END_() {on_patterns(); next}
$0 == ACTIONS(), $0 == END_()  {on_actions(); next}
$0 ~ /^[[:space:]]*$/ {next} # ignore empty lines
$0 ~ /^[[:space:]]*#/ {next} # ignore comments
{on_else()}

END {
	if (!should_skip_end())
		on_end()
}
# </base>
# </lb_common>
#@ <awklib_ch_num>
#@ Library: ch_num
#@ Description: Translates character to numbers and numbers to
#@ characters for the range 0,127 inclusive, i.e. ASCII if that's your
#@ underlying character set.
#@ Version: 1.0
##
## Vladimir Dinev
## vld.dinev@gmail.com
## 2021-08-30
#@

#
#@ Description: Initializes the char/num tables.
#@ Returns: Nothing.
#
function ch_num_init(    _i, _ch) {
	
	for (_i = 0; _i <= 127; ++_i) {
		
		_ch = sprintf("%c", _i)
		
		if (0x00 == _i) {_ch = "\\0"}
		else if (0x07 == _i) { _ch = "\\a"}
		else if (0x08 == _i) { _ch = "\\b"}
		else if (0x09 == _i) { _ch = "\\t"}
		else if (0x0A == _i) { _ch = "\\n"}
		else if (0x0B == _i) { _ch = "\\v"}
		else if (0x0C == _i) { _ch = "\\f"}
		else if (0x0D == _i) { _ch = "\\r"}
		else if (0x1B == _i) { _ch = "\\e"}
		
		__LB_ch_num_ch_to_num__[_ch] = _i
		__LB_ch_num_num_to_ch__[_i] = _ch
	}
}

#
#@ Description: Translates the character 'ch' to a number.
#@ Returns: The number representation of 'ch'.
#
function ch_to_num(ch) {return (__LB_ch_num_ch_to_num__[ch]+0)}

#
#@ Description: Translates the number 'num' to a character.
#@ Returns: The character representation of 'num'.
#
function num_to_ch(num) {return (__LB_ch_num_num_to_ch__[num] "")}
#@ </awklib_ch_num>
#@ <awklib_array>
#@ Library: arr
#@ Description: Array functionality.
#@ Version: 1.0
##
## Vladimir Dinev
## vld.dinev@gmail.com
## 2021-08-20
#@

#
#@ Description: Clears 'arr'.
#@ Returns: Nothing.
#@ Complexity: O(1)
#
function arr_init(arr) {

	arr[""]
	delete arr
}

#
#@ Description: Clears 'arr_dest', puts all keys of 'map' in 'arr_dest'.
#@ Returns: Nothing.
#@ Complexity: O(n)
#
function arr_from_map_keys(arr_dest, map,    _i, _n) {
	
	delete arr_dest
	_i = 0
	for (_n in map)
		arr_dest[++_i] = _n
	return _i
}

#
#@ Description: Clears 'arr_dest', puts all values of 'map' in
#@ 'arr_dest'.
#@ Returns: Nothing.
#@ Complexity: O(n)
#
function arr_from_map_vals(arr_dest, map,    _i, _n) {
	
	delete arr_dest
	_i = 0
	for (_n in map)
		arr_dest[++_i] = map[_n]
	return _i
}

#
#@ Description: Clears 'arr_dest' and copies the range defined by
#@ 'src_begin' and 'src_end' from 'arr_src' to 'arr_dest'. The range is
#@ inclusive. If 'src_begin' is larger than 'src_end', nothing is
#@ copied.
#@ Returns: The length of 'arr_dest'.
#@ Complexity: O(n)
#
function arr_range(arr_dest, arr_src, src_begin, src_end,    _i, _n) {
	
	delete arr_dest
	_n = 0
	for (_i = src_begin; _i <= src_end; ++_i)
		arr_dest[++_n] = arr_src[_i]
	return _n
}

#
#@ Description: Clears 'arr_dest' and copies 'arr_src' into 'arr_dest'.
#@ Returns: The length of 'arr_dest'.
#@ Complexity: O(n)
#
function arr_copy(arr_dest, arr_src, src_len) {

	return arr_range(arr_dest, arr_src, 1, src_len)
}

#
#@ Description: Appends 'arr_src' to the end of 'arr_dest'.
#@ Returns: The length of 'arr_dest' after appending.
#@ Complexity: O(n)
#
function arr_append(arr_dest, dest_len, arr_src, src_len,    _i) {

	for (_i = 1; _i <= src_len; ++_i)
		arr_dest[++dest_len] = arr_src[_i]
	return dest_len
}

#
#@ Description: Clears 'arr_dest', places all elements from 'arr_src'
#@ which are at indexes contained in 'arr_ind' in 'arr_dest'. E.g. given
#@ 'arr_ind[1] = 5; arr_ind[2] = 6', 'arr_dest' will get
#@ 'arr_dest[1] = arr_src[5]; arr_dest[2] = arr_src[6]'
#@ Returns: The length of 'arr_dest'.
#@ Complexity: O(n)
#
function arr_gather(arr_dest, arr_src, arr_ind, ind_len,    _i, _n) {
	
	delete arr_dest
	_n = 0
	for (_i = 1; _i <= ind_len; ++_i)
		arr_dest[++_n] = arr_src[arr_ind[_i]]
	return _n
}

#
#@ Description: Finds the index of the first match for 'regex' in 'arr'.
#@ Returns: The index of the first match, 0 if not match is found.
#@ Complexity: O(n)
#
function arr_match_ind_first(arr, len, regex,    _i) {
	
	for (_i = 1; _i <= len; ++_i) {
		if (match(arr[_i], regex))
			return _i
	}
	return 0
}

#
#@ Description: Clears 'arr_dest', places the indexes for all matches
#@ for 'regex' in 'arr_src' in 'arr_dest'.
#@ Returns: The length of 'arr_dest'.
#@ Complexity: O(n)
#
function arr_match_ind_all(arr_dest, arr_src, src_len, regex,    _i,
_n) {
	
	delete arr_dest
	_n = 0
	for (_i = 1; _i <= src_len; ++_i) {
		if (match(arr_src[_i], regex))
			arr_dest[++_n] = _i
	}
	return _n
}

#
#@ Description: Clears 'arr_dest' and copies all elements which match
#@ 'regex' from 'arr_src' to 'arr_dest'.
#@ Returns: The length of 'arr_dest'.
#@ Complexity: O(n)
#
function arr_match(arr_dest, arr_src, src_len, regex,    _i, _n) {

	delete arr_dest
	_n = 0
	for (_i = 1; _i <= src_len; ++_i) {
		if (match(arr_src[_i], regex))
			arr_dest[++_n] = arr_src[_i]
	}
	return _n
}

#
#@ Description: Finds the index of the first non-match for 'regex' in
#@ 'arr'.
#@ Returns: The index of the first non-match, 0 if all match.
#@ Complexity: O(n)
#
function arr_dont_match_ind_first(arr, len, regex,    _i) {
	
	for (_i = 1; _i <= len; ++_i) {
		if (!match(arr[_i], regex))
			return _i
	}
	return 0
}

#
#@ Description: Clears 'arr_dest', places the indexes for all
#@ non-matches for 'regex' in 'arr_src' in 'arr_dest'.
#@ Returns: The length of 'arr_dest'.
#@ Complexity: O(n)
#
function arr_dont_match_ind_all(arr_dest, arr_src, src_len, regex,
    _i, _n) {
	
	delete arr_dest
	_n = 0
	for (_i = 1; _i <= src_len; ++_i) {
		if (!match(arr_src[_i], regex))
			arr_dest[++_n] = _i
	}
	return _n
}

#
#@ Description: Clears 'arr_dest' and copies all elements which do not
#@ match 'regex' from 'arr_src' to 'arr_dest'.
#@ Returns: The length of 'arr_dest'.
#@ Complexity: O(n)
#
function arr_dont_match(arr_dest, arr_src, src_len, regex,    _i, _n) {

	delete arr_dest
	_n = 0
	for (_i = 1; _i <= src_len; ++_i) {
		if (!match(arr_src[_i], regex))
			arr_dest[++_n] = arr_src[_i]
	}
	return _n
}

#
#@ Description: Calls 'sub()' for every element of 'arr' like
#@ 'sub(regex, subst, arr[i])'
#@ Returns: The number of substitutions made.
#@ Complexity: O(n)
#
function arr_sub(arr, len, regex, subst,    _i, _n) {

	_n = 0
	for (_i = 1; _i <= len; ++_i)
		_n += sub(regex, subst, arr[_i])
	return _n
}

#
#@ Description: Calls gsub() for every element of 'arr' like
#@ 'gsub(regex, subst, arr[i])'
#@ Returns: The number of substitutions made.
#@ Complexity: O(n)
#
function arr_gsub(arr, len, regex, subst,    _i, _n) {

	_n = 0
	for (_i = 1; _i <= len; ++_i)
		_n += gsub(regex, subst, arr[_i])
	return _n
}

#
#@ Description: Checks if 'arr_a' and 'arr_b' have the same elements.
#@ Returns: 1 if the arrays are equal, 0 otherwise.
#@ Complexity: O(n)
#
function arr_is_eq(arr_a, len_a, arr_b, len_b,    _i) {

	if (len_a != len_b)
		return 0
	for (_i = 1; _i <= len_a; ++_i) {
		if (arr_a[_i] != arr_b[_i])
			return 0
	}
	return 1
}

#
#@ Description: Finds 'val' in 'arr'.
#@ Returns: The index of 'val' if it's found, 0 otherwise.
#@ Complexity: O(n)
#
function arr_find(arr, len, val,    _i) {
	
	for (_i = 1; _i <= len; ++_i) {
		if (arr[_i] == val)
			return _i
	}
	return 0
}

#
#@ Description: Concatenates all elements of 'arr' into a single string.
#@ The elements are separated by 'sep'. It 'sep' is not given, " " is
#@ used. 'sep' does not appear after the last element.
#@ Returns: The string representation of 'arr'.
#@ Complexity: O(n)
#
function arr_to_str(arr, len, sep,    _i, _str) {
	
	if (len < 1)
		return ""
	
	if (!sep)
		sep = " "
		
	_str = arr[1]
	for (_i = 2; _i <= len; ++_i)
		_str = (_str sep arr[_i])
	
	return _str
}

#
#@ Description: Prints 'arr' to stdout.
#@ Returns: Nothing.
#@ Complexity: O(n)
#
function arr_print(arr, len, sep) {

	print arr_to_str(arr, len, sep)
}
#@ </awklib_array>
#@ <awklib_vect>
#@ Library: vect
#@ Description: Vector functionality. A vector is as array which is
#@ aware of its own size.
#@ Dependencies: awklib_array.awk
#@ Version: 1.0
##
## Vladimir Dinev
## vld.dinev@gmail.com
## 2021-08-20
#@

#
#@ Description: Clears 'vect', initializes it with length 0.
#@ Returns: Nothing.
#@ Complexity: O(1)
#
function vect_init(vect) {

	vect[""]
	delete vect
	vect[_VECT_LEN()] = 0
}

#
#@ Description: Initializes 'vect' to a copy of 'arr'.
#@ Returns: Nothing.
#@ Complexity: O(n)
#
function vect_init_arr(vect, arr, len,    _i) {
	
	vect_init(vect)
	for (_i = 1; _i <= len; ++_i)
		vect[++vect[_VECT_LEN()]] = arr[_i]
}

#
#@ Description: Appends 'val' to 'vect'.
#@ Returns: Nothing.
#@ Complexity: O(1)
#
function vect_push(vect, val) {

	vect[++vect[_VECT_LEN()]] = val
}

#
#@ Description: Appends 'arr' to 'vect'.
#@ Returns: Nothing.
#@ Complexity: O(n)
#
function vect_push_arr(vect, arr, len,    _i) {

	for (_i = 1; _i <= len; ++_i)
		vect[++vect[_VECT_LEN()]] = arr[_i]
}

#
#@ Description: Retrieves the last value from 'vect'.
#@ Returns: The last element.
#@ Complexity: O(1)
#
function vect_peek(vect) {

	return vect[vect[_VECT_LEN()]]
}

#
#@ Description: Removes the last element of 'vect'.
#@ Returns: Nothing.
#@ Complexity: O(1)
#
function vect_pop(vect) {

	vect[--vect[_VECT_LEN()]]
}

#
#@ Description: Provides the length.
#@ Returns: The length of 'vect'.
#@ Complexity: O(1)
#
function vect_len(vect) {
	
	return vect[_VECT_LEN()]
}

#
#@ Description: Indicates if 'vect' is empty or not.
#@ Returns: 1 if 'vect' is empty, 0 otherwise.
#@ Complexity: O(1)
#
function vect_is_empty(vect) {

	return (!vect[_VECT_LEN()])
}

#
#@ Description: Removes the element in 'vect' at index 'ind' by moving
#@ all further elements one to the left.
#@ Returns: Nothing.
#@ Complexity: O(n)
#
function vect_del_ind(vect, ind,    _i, _len) {
	
	_len = vect[_VECT_LEN()]
	for (_i = ind; _i < _len; ++_i)
		vect[_i] = vect[_i+1]
	--vect[_VECT_LEN()]
}

#
#@ Description: Removes 'val' from 'vect' by  if (arr_find())
#@ vect_del_ind().
#@ Returns: Nothing.
#@ Complexity: O(n)
#
function vect_del_val(vect, val,    _ind) {
	
	if (_ind = arr_find(vect, vect[_VECT_LEN()], val))
		vect_del_ind(vect, _ind)
}

#
#@ Description: Removes the element at 'ind' from 'vect' by replacing it
#@ with the last element.
#@ Returns: Nothing
#@ Complexity: O(1)
#
function vect_swap_pop_ind(vect, ind) {
	
	vect[ind] = vect[vect[_VECT_LEN()]]
	--vect[_VECT_LEN()]
}

#
#@ Description: Removes the first instance of 'val' from 'vect' by
#@ if (arr_find()) vect_swap_pop_ind().
#@ Returns: Nothing.
#@ Complexity: O(1)
#
function vect_swap_pop_val(vect, val, _ind) {

	if (_ind = arr_find(vect, vect[_VECT_LEN()], val))
		vect_swap_pop_ind(vect, _ind)
}

function _VECT_LEN() {return "len"}
#@ </awklib_vect>
#@ <awklib_eos>
#@ Library: eos
#@ Description: An entry order set. Implemented in terms of a vector.
#@ The elements appear in the order they were entered.
#@ Dependencies: awklib_vect.awk
#@ Version: 1.0
##
## Vladimir Dinev
## vld.dinev@gmail.com
## 2021-08-20
#@

#
#@ Description: Clears 'eos'.
#@ Returns: Nothing.
#@ Complexity: O(1)
#
function eos_init(eos) {
	
	vect_init(eos)
}

#
#@ Description: 'eos' is initialized to a set created from 'arr'.
#@ Returns: Nothing.
#@ Complexity: O(n)
#
function eos_init_arr(eos, arr, len,    _i) {

	vect_init(eos)
	for (_i = 1; _i <= len; ++_i)
		eos_add(eos, arr[_i])
}

#
#@ Description: Adds 'val' to 'eos' only if 'val' is not already there.
#@ Returns: Nothing.
#@ Complexity: O(n)
#
function eos_add(eos, val) {
	
	if (!arr_find(eos, vect_len(eos), val))
		vect_push(eos, val)
}

#
#@ Description: If found, removes 'val' from 'eos'. Keeps the relative
#@ order.
#@ Returns: Nothing.
#@ Complexity: O(n)
#
function eos_del(eos, val) {
	
	vect_del_val(eos, val)
}

#
#@ Description: Indicates if 'val' exists in 'eos'.
#@ Returns: 0 if 'val' is not found, the index of 'val' in 'eos'
#@ otherwise.
#@ Complexity: O(n)
#
function eos_has(eos, val) {
	
	return arr_find(eos, vect_len(eos), val)
}

#
#@ Description: Indicates the size of 'eos'.
#@ Returns: The number of elements.
#@ Complexity: O(1)
#
function eos_size(eos) {
	
	return vect_len(eos)
}

#
#@ Description: Indicates if 'eos' is empty.
#@ Returns: 1 if 'eos' is empty, 0 otherwise.
#@ Complexity: O(1)
#
function eos_is_empty(eos) {

	return vect_is_empty(eos)
}

#
#@ Description: 'eos_dest' gets all elements from both 'eos_a' and
#@ 'eos_b'.
#@ Returns: Nothing.
#@ Complexity: O(n)
#
function eos_union(eos_dest, eos_a, eos_b,    _i, _len) {
	
	vect_init(eos_dest)
	
	_len = vect_len(eos_a)
	for (_i = 1; _i <= _len; ++_i)
		eos_add(eos_dest, eos_a[_i])
	
	_len = vect_len(eos_b)
	for (_i = 1; _i <= _len; ++_i)
		eos_add(eos_dest, eos_b[_i])
}

#
#@ Description: 'eos_dest' gets all elements from 'eos_a' which are also
#@ in 'eos_b'.
#@ Returns: Nothing.
#@ Complexity: O(n)
#
function eos_intersect(eos_dest, eos_a, eos_b,    _i, _len) {
	
	vect_init(eos_dest)
	
	_len = vect_len(eos_a)
	for (_i = 1; _i <= _len; ++_i) {
		if (eos_has(eos_b, eos_a[_i]))
			vect_push(eos_dest, eos_a[_i])
	}
}

#
#@ Description: 'eos_dest' gets all elements from 'eos_a' which are not
#@ in 'eos_b'.
#@ Returns: Nothing.
#@ Complexity: O(n)
#
function eos_subtract(eos_dest, eos_a, eos_b,    _i, _len) {
	
	vect_init(eos_dest)
	
	_len = vect_len(eos_a)
	for (_i = 1; _i <= _len; ++_i) {
		if (!eos_has(eos_b, eos_a[_i]))
			vect_push(eos_dest, eos_a[_i])
	}
}

#
#@ Description: Indicates if the intersection of 'eos_a' and 'eos_b' is
#@ empty.
#@ Returns: 1 if it is, 0 otherwise.
#@ Complexity: O(n)
#
function eos_are_disjoint(eos_a, eos_b,    _eos_tmp) {
	
	eos_intersect(_eos_tmp, eos_a, eos_b)
	return eos_is_empty(_eos_tmp)
}

#
#@ Description: Indicates if 'eos_a' is a subset of 'eos_b'.
#@ Returns: 1 if it is, 0 otherwise.
#@ Complexity: O(n)
#
function eos_is_subset(eos_a, eos_b,    _i, _len) {
	
	_len = vect_len(eos_a)
	for (_i = 1; _i <= _len; ++_i) {
		if (!eos_has(eos_b, eos_a[_i]))
			return 0
	}
	return 1
}
#@ </awklib_eos>
#@ <awklib_tabs>
#@ Library: tabs
#@ Description: String indentation.
#@ Version: 1.0
##
## Vladimir Dinev
## vld.dinev@gmail.com
## 2021-08-16
#@

#
#@ Description: Adds a tab to the indentation string.
#@ Returns: Nothing.
#
function tabs_inc() {

	++__LB_tabs_tabs_num__
	__LB_tabs_tabs_str__ = (__LB_tabs_tabs_str__ "\t")
}

#
#@ Description: Removes a tab from the indentation string.
#@ Returns: Nothing.
#
function tabs_dec() {

	if (__LB_tabs_tabs_num__) {
		--__LB_tabs_tabs_num__
		__LB_tabs_tabs_str__ = substr(__LB_tabs_tabs_str__, 1,
			__LB_tabs_tabs_num__)
	}
}

#
#@ Description: Indicates the tab level.
#@ Returns: The number of tabs used for indentation.
#
function tabs_num() {

	return __LB_tabs_tabs_num__
}

#
#@ Description: Provides all indentation tabs as a string.
#@ Returns: The indentation string.
#
function tabs_get() {

	return (__LB_tabs_tabs_str__ "")
}

#
#@ Description: Adds indentation to 'str'.
#@ Returns: 'str' prepended with the current number of tabs.
#
function tabs_indent(str) {

	return (__LB_tabs_tabs_str__ str)
}

#
#@ Description: Prints the indented 'str' to stdout without a new line
#@ at the end.
#@ Returns: Nothing.
#
function tabs_print_str(str) {

	printf("%s", tabs_indent(str))
}

#
#@ Description: Prints the indented 'str' to stdout with a new line at
#@ the end.
#@ Returns: Nothing.
#
function tabs_print(str) {

	print tabs_indent(str)
}
#@ </awklib_tabs>
#@ <awklib_prog>
#@ Library: prog
#@ Description: Provides program name, error, and exit handling. Unlike
#@ other libraries, the function names for this library are not
#@ prepended.
#@ Version 1.0
##
## Vladimir Dinev
## vld.dinev@gmail.com
## 2021-08-15
#@

#
#@ Description: Sets the program name to 'str'. This name can later be
#@ retrieved by get_program_name().
#@ Returns: Nothing.
#
function set_program_name(str) {

	__LB_prog_program_name__ = str
}

#
#@ Description: Provides the program name.
#@ Returns: The name as set by set_program_name().
#
function get_program_name() {

	return __LB_prog_program_name__
}

#
#@ Description: Prints 'msg' to stderr.
#@ Returns: Nothing.
#
function pstderr(msg) {

	print msg > "/dev/stderr"
}

#
#@ Description: Sets a static flag which can later be checked by
#@ should_skip_end().
#@ Returns: Nothing.
#
function skip_end_set() {

	__LB_prog_skip_end_flag__ = 1
}

#
#@ Description: Clears the flag set by skip_end_set().
#@ Returns: Nothing.
#
function skip_end_clear() {

	__LB_prog_skip_end_flag__ = 0
}

#
#@ Description: Checks the static flag set by skip_end_set().
#@ Returns: 1 if the flag is set, 0 otherwise.
#
function should_skip_end() {

	return (__LB_prog_skip_end_flag__+0)
}

#
#@ Description: Sets a static flag which can later be checked by
#@ did_error_happen().
#@ Returns: Nothing
#
function error_flag_set() {

	__LB_prog_error_flag__ = 1
}

#
#@ Description: Clears the flag set by error_flag_set().
#@ Returns: Nothing
#
function error_flag_clear() {

	__LB_prog_error_flag__ = 0
}

#
#@ Description: Checks the static flag set by error_flag_set().
#@ Returns: 1 if the flag is set, 0 otherwise.
#
function did_error_happen() {

	return (__LB_prog_error_flag__+0)
}

#
#@ Description: Sets the skip end flag, exits with error code 0.
#@ Returns: Nothing.
#
function exit_success() {
	
	skip_end_set()
	exit(0)
}

#
#@ Description: Sets the skip end flag, exits with 'code', or 1 if 'code' is 0
#@ or not given.
#@ Returns: Nothing.
#
function exit_failure(code) {

	skip_end_set()
	exit((code+0) ? code : 1)
}

#
#@ Description: Prints '<program-name>: error: msg' to stderr. Sets the
#@ error and skip end flags.
#@ Returns: Nothing.
#
function error_print(msg) {

	pstderr(sprintf("%s: error: %s", get_program_name(), msg))
	error_flag_set()
	skip_end_set()
}

#
#@ Description: Calls error_print() and quits with failure.
#@ Returns: Nothing.
#
function error_quit(msg, code) {

	error_print(msg)
	exit_failure(code)
}
#@ </awklib_prog>
#@ <awklib_prefix_tree>
#@ Library: pft
#@ Description: A prefix tree implementation. E.g. conceptually, if you
#@ insert "this" and "that", you'd get:
#@ pft["t"] = "h"
#@ pft["th"] = "ia"
#@ pft["thi"] = "s"
#@ pft["this"] = ""
#@ pft["tha"] = "t"
#@ pft["that"] = ""
#@ However, all units must be separated by PFT_SEP(), so in this case
#@ "this" should be ("t" PFT_SEP() "h" PFT_SEP() "i" PFT_SEP() "s").
#@ Similar for "that". PFT_SEP() is a non-printable character. To make
#@ any key or value from a pft printable, use pft_pretty().
#@ Version: 1.2
##
## Vladimir Dinev
## vld.dinev@gmail.com
## 2022-01-14
#@

# "\034" is inlined as a constant; make sure it's in sync with PFT_SEP()
function _PFT_LAST_NODE() {

	return "\034[^\034]+$"
}

# <public>
#@ Description: The prefix tree path delimiter.
#@ Returns: Some non-printable character.
#
function PFT_SEP() {

	return "\034"
}

#
#@ Description: Clears 'pft'.
#@ Returns: Nothing.
#@ Complexity: O(1)
#
function pft_init(pft) {

	pft[""]
	delete pft
}

#
#@ Description: Inserts 'path' in 'pft'. 'path' has to be a PFT_SEP() delimited
#@ string.
#@ Returns: Nothing.
#@ Complexity: O(n)
#
function pft_insert(pft, path,    _val) {
# inserts "a.b.c", "a.x.y" backwards, so you get
# pft["a.b.c"] = ""
# pft["a.b"] = "c"
# pft["a"] = "b"
# pft["a.x.y"] = ""
# pft["a.x"] = "y"
# pft["a"] = "b.x"

	if (!path)
		return

	_pft_add(pft, path, _val)

	if (match(path, _PFT_LAST_NODE())) {
		_val = substr(path, RSTART+1)
		path = substr(path, 1, RSTART-1)
	} else {
		return
	}

	pft_insert(pft, path, _val)
}

#
#@ Description: If 'path' exists in 'pft', makes 'path' and all paths stemming
#@ from 'path' unreachable. 'path' has to be a PFT_SEP() delimited string.
#@ Returns: Nothing.
#@ Complexity: O(n)
#
function pft_rm(pft, path,    _arr, _arr2, _i, _len, _last, _no_tail, _tmp) {

	if (pft_has(pft, path)) {

		delete pft[path]

		if ((_len = pft_split(_arr, path)) > 1) {

			_last = _arr[_len]
			_no_tail = pft_arr_to_pft_str(_arr, _len-1)

			_len = pft_split(_arr, pft[_no_tail])

			_tmp = 0
			for (_i = 1; _i <= _len; ++_i) {

				if (_arr[_i] != _last)
					_arr2[++_tmp] = _arr[_i]
			}

			pft[_no_tail] = pft_arr_to_pft_str(_arr2, _tmp)
		}
	}
}

#
#@ Description: Marks 'path' in 'pft', so pft_is_marked() will return
#@ 1 when asked about 'path'. The purpose of this is so also
#@ intermediate paths, and not only leaf nodes, can be considered during
#@ traversal. E.g. if you insert "this", "than", and "thank" in 'pft'
#@ and want to get these words out again, when you traverse only "this"
#@ and "thank" will be leaf nodes in the pft. Unless "than" is somehow
#@ marked, you will have no way to know "than" is actually a word, and
#@ not only an intermediate path to "thank", like "tha" would be.
#@ Returns: Nothing.
#@ Complexity: O(1)
#
function pft_mark(pft, path) {

	pft[(_PFT_MARK_SEP() path)]
}

#
#@ Description: Indicates if 'path' is marked in 'pft'.
#@ Returns: 1 if it is, 0 otherwise.
#@ Complexity: O(1)
#
function pft_is_marked(pft, path) {

	return ((_PFT_MARK_SEP() path) in pft)
}

#
#@ Description: Unmarks 'path' from 'pft' if it was previously marked.
#@ Returns: Nothing.
#@ Complexity: O(1)
#
function pft_unmark(pft, path) {

	if (pft_is_marked(pft, path))
		delete pft[(_PFT_MARK_SEP() path)]
}

#
#@ Description: Retrieves 'key' from 'pft'.
#@ Returns: pft[key] if 'key' exists in 'pft', the empty string
#@ otherwise. Use only if pft_has() has returned 1.
#@ Complexity: O(1)
#
function pft_get(pft, key) {

	return pft_has(pft, key) ? pft[key] : ""
}

#
#@ Description: Indicates whether 'key' exists in 'pft'.
#@ Returns: 1 if 'key' is found in 'pft', 0 otherwise.
#@ Complexity: O(1)
#
function pft_has(pft, key) {

	return (key in pft)
}

#
#@ Description: Splits 'pft_str' in 'arr' using PFT_SEP() as a
#@ separator. I.e. Splits what pft_get() returns.
#@ Returns: The length of 'arr'.
#@ Complexity: O(n)
#
function pft_split(arr, pft_str) {

	return split(pft_str, arr, PFT_SEP())
}


#
#@ Description: Splits 'pft_str', finds out if 'node' exists in
#@ the array created by the split.
#@ Returns: 1 if 'node' is a path in 'pft_str', 0 otherwise.
#@ Complexity: O(n)
#
function pft_path_has(pft_str, node,    _i, _len, _arr) {

	_len = pft_split(_arr, pft_str)
	for (_i = 1; _i <= _len; ++_i) {
		if (_arr[_i] == node)
			return 1
	}
	return 0
}

#
#@ Description: Turns 'arr' into a PFT_SEP() delimited string.
#@ Returns: The pft string representation of 'arr'.
#@ Complexity: O(n)
#
function pft_arr_to_pft_str(arr, len,    _i, _str) {

	_str = ""
	for (_i = 1; _i < len; ++_i)
		_str = (_str arr[_i] PFT_SEP())
	if (_i == len)
		_str = (_str arr[_i])
	return _str
}

#
#@ Description: Delimits the strings 'a' and 'b' with PFT_SEP().
#@ Returns: If only b is empty, returns a. If only a is empty, returns
#@ b. If both are empty, returns the empty string. Returns
#@ (a PFT_SEP() b) otherwise.
#@ Complexity: O(awk-concatenation)
#
function pft_cat(a, b) {

	if (("" != a) && ("" != b)) return (a PFT_SEP() b)
	if ("" == b) return a
	if ("" == a) return b
	return ""
}

#
#@ Description: Replaces all internal separators in 'pft_str' with
#@ 'sep'. If 'sep' is not given, "." is used.
#@ Returns: A printable representation of 'pft_str'.
#@ Complexity: O(n)
#
function pft_pretty(pft_str, sep) {

	gsub((PFT_SEP() "|" _PFT_MARK_SEP()), ((!sep) ? "." : sep), pft_str)
	return pft_str
}

#
#@ Description: Builds a string by performing a depth first search
#@ traversal of 'pft' starting from 'root'. The end result is all marked
#@ and leaf nodes subseparated by 'subsep' in their order of insertion
#@ separated by 'sep'. If 'sep' is not given, " " is used. If 'subsep'
#@ is not given, PFT_SEP() is removed from the node strings. E.g. for
#@ the words "this" and "that", if 'sep' is " -> "
#@ If 'subsep' is blank, the result shall be
#@ "this -> that"
#@ If 'subsep' is '-', the result shall be
#@ "t-h-i-s -> t-h-a-t"
#@ 'sep' does not appear after the last element.
#@ Returns: A string representation 'pft'.
#@ Complexity: O(n)
#
function pft_to_str_dfs(pft, root, sep, subsep,    _arr, _i, _len, _str,
_tmp) {

	if (!pft_has(pft, root))
		return ""

	if (!(_get = pft_get(pft, root)))
		return root

	if (pft_is_marked(pft, root))
		_str = root

	if (!sep)
		sep = " "

	_tmp = ""
	_len = pft_split(_arr, _get)
	for (_i = 1; _i <= _len; ++_i) {

		if (_tmp = pft_to_str_dfs(pft, pft_cat(root, _arr[_i]),
			sep, subsep)) {
			_str = (_str) ? (_str sep _tmp) : _tmp
		}
	}

	gsub(PFT_SEP(), subsep, _str)
	return _str
}

#
#@ Description: Prints the string representation of 'pft' to stdout as
#@ returned by pft_to_str_dfs().
#@ Returns: Nothing.
#@ Complexity: O(n)
#
function pft_print_dfs(pft, root, sep, subsep) {

	print pft_to_str_dfs(pft, root, sep, subsep)
}

#
#@ Description: Returns the dump of 'pft' as a single multi line string
#@ in the format "pft[<key>] = <val>" in no particular order. Marked
#@ nodes always begin with 'sep'.
#@ Returns: Nothing.
#@ Complexity: O(n)
#
function pft_str_dump(pft, sep,    _n, _str, _ret) {

	for (_n in pft) {
		_str = sprintf("pft[\"%s\"] = \"%s\"",
				pft_pretty(_n, sep), pft_pretty(pft[_n], sep))
		_ret = (_ret) ? (_ret "\n" _str) : _str
	}
	return _ret
}

#
#@ Description: Prints the dump of 'pft to stdout as returned by
#@ pft_str_dump().
#@ Returns: Nothing.
#@ Complexity: O(n)
#
function pft_print_dump(pft, sep) {

	print pft_str_dump(pft, sep)
}
# </public>

function _pft_add(pft, key, val,    _get) {

	if ((_get = pft_get(pft, key))) {
		if (val && !pft_path_has(_get, val)) {
			pft[key] = pft_cat(_get, val)
		}
	} else {
		pft[key] = val
	}
}

function _PFT_MARK_SEP() {return "mark\006"}
#@ </awklib_prefix_tree>
